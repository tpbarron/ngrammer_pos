<p>FOR decades navies have employed human divers, dolphins and sea lions to search for explosives attached to the hulls of warships by a scuba-diving enemy. Although these mine-finding tactics work, they are less than ideal. Divers can be killed or injured and marine mammals are extremely costly to maintain on a boat. Mines are also getting smaller and harder to detect. The idea of using aquatic robots to search for the mines instead is alluring, but it is difficult to teach machines how to navigate around hulls without crashing into them or getting lost. Franz Hover and Brendan Englot at the Massachusetts Institute of Technology (MIT) have come up with a way to improve things by using a two-step process.</p>

<p>Programming robots to scan hulls would be relatively easy if limpet mines were still as large as watermelons. The robot would simply be told to maintain a safe working distance and swim back and forth, using its sonar scanners to generate an image of the hull’s topography. If the resulting image perfectly matched that of a clean hull stored in the robot’s memory, it could be safely assumed that there were no mines attached. If not it could raise an alarm. Yet nowadays mines can be as tiny as a mobile phone. Such a mine might not blast a hole in the hull, but if carefully placed it could disable a ship’s propellers.</p>

<p>The problem, then, is one of definition. Sonar scans done at a safe distance of 10 metres create a rough image known as a data-point cloud. But this lacks the detail necessary to spot small explosive charges. The addition of video cameras may not do much to help, because harbour waters are often murky. To work around these problems, Dr Hover came up with the idea of using the data-point cloud not to spot mines, but as a guide to help the robot take a closer look at the hull.</p>

<p>With this in mind Dr Hover and Mr Englot, along with a team of colleagues, used a robot known as the Hovering Autonomous Underwater Vehicle (HAUV), which was developed at MIT and has since been commercialised by a company called Bluefin Robotics. The robot was programmed to create a data-point cloud using a traditional sonar scan. This grainy image was then processed by an algorithm designed to connect the data points and create a three-dimensional grid map that the HAUV could use as a guide for moving in closer, to perform a second scan at a distance of one metre. (In the image above, the robot is shown in yellow, and the range of its sonar scanner in red.)</p>

<p>Early results are promising. Letting the newly programmed HAUV loose on the Curtiss, a 183-metre military-support ship in San Diego, and the Seneca, an 82-metre cutter in Boston, showed that a robot can do the job. First, a scan at a range of 8 metres generated a 3D model. This was then used as a guide for a close-up inspection of the tight and tucked-away spaces between the propeller, shafting, rudder and hull. “If there is a need to see everything on the hull in great detail, the robots win big,” says Dr Hover. Bluefin has a $30m contract from the US Navy to develop the HAUV with MIT.</p>

<p>Robots are not about to take over all hull examinations, however. The HAUV was less successful at carrying out its task when working in strong or complex currents of the sort that trained marine mammals would simply ignore. So in some conditions the dolphins and sea lions will continue to have a clear advantage—for the time being, at least.</p>

